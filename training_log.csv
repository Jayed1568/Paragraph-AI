loss,grad_norm,learning_rate,epoch,step,train_runtime,train_samples_per_second,train_steps_per_second,total_flos,train_loss
10.7388,inf,0.0,0.024390243902439025,1,,,,,
9.9274,159.60897827148438,5e-06,0.24390243902439024,10,,,,,
4.7106,4.595523357391357,4.955752212389381e-05,0.4878048780487805,20,,,,,
0.7589,3.275134325027466,4.5132743362831855e-05,0.7317073170731707,30,,,,,
0.6454,1.8122520446777344,4.0707964601769914e-05,0.975609756097561,40,,,,,
0.4245,2.633094072341919,3.628318584070797e-05,1.2195121951219512,50,,,,,
0.3915,2.8156168460845947,3.185840707964602e-05,1.4634146341463414,60,,,,,
0.4313,3.006190299987793,2.743362831858407e-05,1.7073170731707317,70,,,,,
0.3806,3.1478981971740723,2.3008849557522124e-05,1.951219512195122,80,,,,,
0.4044,2.8917124271392822,1.858407079646018e-05,2.1951219512195124,90,,,,,
0.3107,1.676104187965393,1.415929203539823e-05,2.4390243902439024,100,,,,,
0.3709,2.1412785053253174,9.734513274336284e-06,2.682926829268293,110,,,,,
0.2686,3.007610321044922,5.3097345132743365e-06,2.926829268292683,120,,,,,
,,,3.0,123,41.0093,5.925,2.999,63493963776000.0,1.5548752431220156
